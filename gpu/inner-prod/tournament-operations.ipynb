{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63760203",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## Tournament sums\n",
    "\n",
    "Burton Rosenberg\n",
    "\n",
    "29 May 2023\n",
    "\n",
    "\n",
    "----\n",
    "\n",
    "\n",
    "\n",
    "The CPU sort of sum loop is $O(n)$. With parallelism it is possible to reduce this to $O(\\log n)$ time, with linear threads by creating a tournement. This is possible with any associative operation. This consists in effect of replacing the parenthesization of, \n",
    "\n",
    "$$\n",
    "S = (a_1+(a_2+(\\ldots + a_n)))\n",
    "$$\n",
    "\n",
    "with any sort of index pattern such as,\n",
    "\n",
    "$$\n",
    "S = ((a_1+a_2)+(a_3+a_4))+((a_5+a_6)+(a_7+a_8))\n",
    "$$\n",
    "\n",
    "This pattern is easily extended out to $n=2^k$, and other values of $n$ are possible with a little care at the edge.\n",
    "\n",
    "There are various patterns this can be done, each represented by a particular loop invariant.\n",
    "\n",
    "### Warp considerations\n",
    "\n",
    "NVidia launches threads in groups of 32, called a _warp_. This is done to collect up the\n",
    "scheduling overhead. \n",
    "\n",
    "- Warps have consecutive thread numbers, 32 aligned.\n",
    "- Warps run exactly that same code line by line.\n",
    "\n",
    "Even though a warp runs the same code, line by line, branches and loops can take different paths in the code flow, called  _warp divergence_. Every thread in a warp runs the same code path, with the results disabled if in the logic of that particular thread, the branch should not be executed.\n",
    "\n",
    "Various ways of arranging the tournament will resuilt in fewer threads being activated. In the folding variant given, since we always work with consecutive array locations, and the array locatins and thread ID's are identified, we keep all the threads in our warps working (until we are below 32).\n",
    "\n",
    "\n",
    "### Thread synchronization considerations\n",
    "\n",
    "The tournament must go in clear stages, with all threads finishing one folding before going on to the next. Since warps will proceed at their own pace, they must be explicitly synchronized at each $k$.\n",
    "\n",
    "#### Thread synchronization on the GPU\n",
    "\n",
    "There are synchronization calls that form a classic synchronization barrier, will all threads must arrive at the barrier before they all then proceed on. However, this synchronization only works in a thread block, and thread blocks are small.\n",
    "\n",
    "#### Thread synchronization using streams\n",
    "\n",
    "The call to launch a kernel, with its thread multiplicity is placed by the CPU in a GPU command stream and run asynchronously from the CPU. If the CPU attempts to launch several kernels one after the other, they will queue up on the GPU immediately returning to the CPU. \n",
    "\n",
    "However, one thread launch will not start until the thread launch proceeding it in the queue has exited. In this way all threads from one launch are completed before any thread in the next launch begins.\n",
    "\n",
    "__Note:__ NVidia makes use of named for default streams. They act a bit differently with respect to synchronization. Also, the copy of data to and from the GPU is synchronized. This is a simple way for a program learns that a thread launch is completed. While the launches are queued immediately and the code in the CPU continues asynchronously, it will block waiting for the data copy of the result from the GPU to the CPU.\n",
    "\n",
    "### Memory considerations\n",
    "\n",
    "The NVidia has many classes of memory of which we shall briefly consider two: global and shared. In our examples here we are using global memory. This memory is accessible in a uniform way by all threads on the GPU.\n",
    "\n",
    "Shared memory is shared between threads in a block, with a different shared memory for each block and no way for a thread to access memory from a block other than its own. Shared memory is also arranged in 32 banks, and reads and writes to each bank occur in parallel.\n",
    "\n",
    "The global memory is simple, but it is not parallelized as are the threads. There will be consierable contention if all threads access different locations. We have ignored this issue and just pretended our memory is extremely fast and we pay no price for concurrent access. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29745d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# summing elements in an array\n",
    "# Accelerate! GPU course\n",
    "#\n",
    "# last-update:\n",
    "#     30 aug 2022 -bjr: created\n",
    "#\n",
    "#\n",
    "\n",
    "# this is a simulation of a GPU algorithm; \n",
    "# the phases are sequential, and should synchronize\n",
    "# the threads are parallel \n",
    "\n",
    "# properties: \n",
    "#    threads used: n/2^i in phase i\n",
    "#    memory accesss: fully independent\n",
    "\n",
    "def total_sum_folding(a): \n",
    "\n",
    "    def above_power_2(x):\n",
    "        i = 1\n",
    "        while i<x:\n",
    "            i *= 2\n",
    "        return i\n",
    "\n",
    "    l_a = above_power_2(len(a))\n",
    "    \n",
    "    def gpu_kernel(thread_idx,a, d):\n",
    "        a[thread_idx] += a[thread_idx+d]\n",
    "        \n",
    "    phase = 0\n",
    "    # the first fold takes care of arrays not a power of two\n",
    "    d = l_a//2\n",
    "    \n",
    "    # thread launch\n",
    "    for thread in range(d):\n",
    "        if (thread+d)<len(a):\n",
    "            gpu_kernel(thread,a, d)\n",
    "\n",
    "    # remaining phasess do not need the length check\n",
    "    d = d//2\n",
    "    \n",
    "    # Loop Invariant, \n",
    "    #    For i = 0, ... , n/2^k-1, cell i contains sum_{j<k} a[i+k*n/2^k]\n",
    "    # Basis: 2^k==n, trivial\n",
    "    # Update: fold the array\n",
    "    # Final: cell 0 has the sum of all a[i]\n",
    "    \n",
    "    while d>0:\n",
    "        phase += 1 # just a notation;\n",
    "        \n",
    "        # thread launch\n",
    "        for thread in range(d):\n",
    "            gpu_kernel(thread,a, d)\n",
    "        d = d//2\n",
    "            \n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "508101d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing total sum between 1000 and 1050 ...\n",
      "** success\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def total_sum_seq(a):\n",
    "    s = 0\n",
    "    for i in range(len(a)):\n",
    "        s += a[i]\n",
    "    a[0] = s\n",
    "    return\n",
    "\n",
    "\n",
    "def testing_total_sum(a,b):\n",
    "\n",
    "    def fill_array(a):\n",
    "        for i in range(len(a)):\n",
    "            a[i] = i\n",
    "        return a\n",
    "\n",
    "    def testing_total_sum_aux(n):\n",
    "        a = [0]*n\n",
    "        \n",
    "        fill_array(a)\n",
    "        total_sum_seq(a)\n",
    "        s_1 = a[0]\n",
    "        \n",
    "        fill_array(a)\n",
    "        total_sum_folding(a)\n",
    "        s_2 = a[0]\n",
    "        \n",
    "        if s_1!=s_2:\n",
    "            return False\n",
    "        return True\n",
    "\n",
    "    print(f'Testing total sum between {a} and {b} ...')\n",
    "    for s in range(a,b):\n",
    "        if not testing_total_sum_aux(s):\n",
    "            print('** error')\n",
    "            return False\n",
    "    print('** success')\n",
    "    print()\n",
    "    return True\n",
    "\n",
    "testing_total_sum(1000,1050)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad385ff3",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Create a different tournament pattern, for instance the one suggest at the beginning of first adding neighbors, then neighbors with lowest bit of the index zero, then neightbors with the two lowest bits of the index zero, etc. Remember to write a loop invariant.\n",
    "\n",
    "To make things a bit different, calculate the maximum value in the array, rather than the sum of all numbers in the array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84eeddaa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
